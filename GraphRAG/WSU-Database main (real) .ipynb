{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semester_July_2024\\Discovery_Project\\personal_work\\GraphRag\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "from typing import List\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import ChatHuggingFace\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from neo4j import GraphDatabase\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(model_name = \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(\n",
    "#     model_id = \"meta-llama/Meta-Llama-3-8B\",\n",
    "#     task = \"text-generation\",\n",
    "#     pipeline_kwargs={\"max_new_tokens\":4096}\n",
    "# )\n",
    "\n",
    "llm = ChatOpenAI(temperature = 0.6, model = \"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['NEO4J_URI'] = 'neo4j+s://99597476.databases.neo4j.io'\n",
    "# os.environ['NEO4J_USERNAME'] = 'neo4j'\n",
    "# os.environ['NEO4J_PASSWORD'] = '7Io74oHv7d1zf4SPYNu7ZJQZc19lMdPFG4_z-clwHwE'\n",
    "# os.environ['NEO4J_DATABASE'] = 'neo4j'\n",
    "# os.environ['AURA_INSTANCEID'] = '99597476'\n",
    "# os.environ['AURA_INSTANCENAME'] = 'Instance01'\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypdf import PdfMerger\n",
    "\n",
    "# pdfs = ['wsu_courses.pdf','international_guide.pdf','international.pdf','english_requirements.pdf']\n",
    "\n",
    "# merger = PdfMerger()\n",
    "\n",
    "# for pdf in pdfs:\n",
    "#     merger.append(pdf)\n",
    "\n",
    "# merger.write(\"wsu-data.pdf\")\n",
    "# merger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PyPDF2 import PdfReader\n",
    "\n",
    "# # Open the PDF file\n",
    "# reader = PdfReader(\"wsu-data.pdf\")\n",
    "\n",
    "# # Extract text from the PDF\n",
    "# text_data = ''\n",
    "# for page in reader.pages:\n",
    "#     text_data += page.extract_text() + '\\n'\n",
    "\n",
    "# # Save the text to a file\n",
    "# with open('wsu-data.txt', 'w', encoding=\"utf-8\") as file:\n",
    "#     file.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# loader = PyPDFLoader(\"wsu-data.pdf\")\n",
    "# documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # a simple function that removes \\n newline from the content\n",
    "# def remove_ws(d):\n",
    "#     text = d.page_content.replace('\\n','')\n",
    "#     d.page_content = text\n",
    "#     return d\n",
    "\n",
    "# # applied on the docs\n",
    "# documents = [remove_ws(d) for d in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "# llm_transformer = LLMGraphTransformer(llm=llm)\n",
    "# graph_documents2 = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Save graph_documents as a Pickle file\n",
    "# with open(\"graph_enhanced.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(graph_documents, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the saved graph documents\n",
    "with open('ultimate_graph.pkl', 'rb') as file:\n",
    "    graph_documents = pickle.load(file)\n",
    "\n",
    "# Open the saved graph documents\n",
    "with open('graph_enhanced.pkl', 'rb') as file:\n",
    "    graph_documents2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(\n",
    "    graph_documents,\n",
    "    baseEntityLabel=True,\n",
    "    include_source=True\n",
    ")\n",
    "\n",
    "graph.add_graph_documents(\n",
    "    graph_documents2,\n",
    "    baseEntityLabel= True,\n",
    "    include_source= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0d40e26d8343da8228d50f2313b00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# directly show the graph resulting from the given Cypher query:\n",
    "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n",
    "\n",
    "def showGraph(cypher: str = default_cypher):\n",
    "    driver = GraphDatabase.driver(\n",
    "        uri = os.environ[\"NEO4J_URI\"],\n",
    "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
    "                os.environ[\"NEO4J_PASSWORD\"]))\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph = session.run(\"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "showGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"vector\"  # default index name\n",
    "keyword_index_name = \"keyword\"  # default keyword index name\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_index(\n",
    "    # OpenAIEmbeddings(model = \"text-embedding-3-large\"),\n",
    "    embed_model,\n",
    "    index_name=index_name,\n",
    "    keyword_index_name=keyword_index_name,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "\n",
    "\n",
    "# vector_index = Neo4jVector.from_existing_graph(\n",
    "#     embed_model,\n",
    "#     # OpenAIEmbeddings(model = \"text-embedding-3-large\"),\n",
    "#     # OllamaEmbeddings(model = \"mxbai-embed-large\"),\n",
    "#     search_type=\"hybrid\",\n",
    "#     node_label=\"Document\",\n",
    "#     text_node_properties=[\"text\"],\n",
    "#     embedding_node_property=\"embedding\"\n",
    "# )\n",
    "\n",
    "retriever = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 4,\n",
       "  'name': 'vector',\n",
       "  'state': 'ONLINE',\n",
       "  'populationPercent': 100.0,\n",
       "  'type': 'VECTOR',\n",
       "  'entityType': 'NODE',\n",
       "  'labelsOrTypes': ['Document'],\n",
       "  'properties': ['embedding'],\n",
       "  'indexProvider': 'vector-2.0',\n",
       "  'owningConstraint': None,\n",
       "  'lastRead': neo4j.time.DateTime(2025, 2, 3, 11, 54, 9, 922000000, tzinfo=<UTC>),\n",
       "  'readCount': 48}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\"\"\"\n",
    "  SHOW VECTOR INDEXES\n",
    "  \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.refresh_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entities(BaseModel):\n",
    "    \"\"\"Identifying information about entities.\"\"\"\n",
    "\n",
    "    names: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"All the person, organization, or business entities that \"\n",
    "        \"appear in the text\",\n",
    "    )\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are extracting organization and person entities from the text.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Use the given format to extract information from the following \"\n",
    "            \"input: {question}\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "structured_llm = llm.with_structured_output(Entities)\n",
    "entity_chain = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "def generate_full_text_query(input: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full-text search query for a given input string.\n",
    "    \n",
    "    This function constructs a query string suitable for a full-text search.\n",
    "    It processes the input string by splitting it into words and combines them\n",
    "    using the AND operator, ensuring exact matches without allowing misspellings.\n",
    "    \"\"\"\n",
    "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
    "    if not words:\n",
    "        return \"\"\n",
    "    full_text_query = \" AND \".join(words)\n",
    "    print(f\"Generated Query: {full_text_query}\")\n",
    "    return full_text_query.strip()\n",
    "\n",
    "\n",
    "# Fulltext index query\n",
    "def graph_retriever(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Collects the neighborhood of entities mentioned\n",
    "    in the question\n",
    "    \"\"\"\n",
    "    if not any(index[\"name\"] == \"entity\" for index in graph.query(\"SHOW INDEXES\")):\n",
    "        graph.query(\"CREATE FULLTEXT INDEX entity FOR (n:__Entity__) ON EACH [n.id]\")\n",
    "    result = \"\"\n",
    "    entities = entity_chain.invoke({\"question\": question})\n",
    "    for entity in entities.names:\n",
    "        response = graph.query(\n",
    "            \"\"\"\n",
    "            CALL db.index.fulltext.queryNodes('entity', $query)\n",
    "            YIELD node,score\n",
    "            CALL {\n",
    "              WITH node\n",
    "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
    "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
    "              UNION ALL\n",
    "              WITH node\n",
    "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
    "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
    "            }\n",
    "            RETURN output LIMIT 50\n",
    "            \"\"\",\n",
    "            {\"query\": generate_full_text_query(entity)},\n",
    "        )\n",
    "        result += \"\\n\".join([el['output'] for el in response])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_retriever(question: str):\n",
    "    graph_data = graph_retriever(question)\n",
    "    vector_data = [el.page_content for el in retriever.invoke(question)]\n",
    "    final_data = f\"\"\"Graph data:\n",
    "{graph_data}\n",
    "vector data:\n",
    "{\"#Document\". join(vector_data)}\n",
    "    \"\"\"\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "template = \"\"\" \n",
    "Answer the question based only on the following context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "- REMEMBER: You are a representative at Western Sydney University, your job is to provide accurate information about \\\n",
    "Western Sydney University to international students who wish to enrol. If you are asked what your role is \\\n",
    "clearly state your role and what you can do.\n",
    "- Use natural language.\n",
    "- For questions that requires simple retrieval, your answer should be concise and informative enough. The entities extracted \\\n",
    "from the query should match exactly with the retrieved information. \n",
    "- For example, you should return the exact match of subjects within a particular degree, do not take subjects that don't belong \\\n",
    "to the degree mentioned in the query.\n",
    "- For question that requires extensive reasoning, try extending your answer to 3 paragraphs, try to connect to \\\n",
    "neighbor entities for more contextually aware response.\n",
    "- If there's no entity matching the query, return \"There is no information in the database regarding what \\\n",
    "you are requesting. Perhaps you should check your spelling or try a different prompt.\"\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "        {\n",
    "            \"context\": full_retriever,\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 4, column: 13, offset: 106} for query: \"\\n            CALL db.index.fulltext.queryNodes('entity', $query)\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Query: parramatta AND south AND campus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: 'CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN node.`text` AS text, score, node {.*, `text`: Null, `embedding`: Null, id: Null } AS metadata'\n"
     ]
    }
   ],
   "source": [
    "query = str(input(\"Enter your query:\"))\n",
    "answer = chain.invoke(input = query.capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parramatta South Campus is a part of Western Sydney University and offers a range of courses and programs for students to enroll in. Located in Parramatta, the campus is home to various facilities such as the Moot Court, Institute for Culture and Society, Science and Psychology Building, and more. Students can study a variety of majors and minors at this campus, including Business Studies, Economy and Markets, Global Business, Gender Studies, and more. The campus also provides learning experiences and opportunities for students to engage with industry professionals and gain practical skills relevant to their future careers.\n",
      "\n",
      "The campus is well-connected to the Parramatta City Campus Precinct and the Parramatta CBD, providing students with access to a vibrant urban environment with various amenities and opportunities. Additionally, the campus offers a supportive learning environment with dedicated staff members such as Dr. Rangika Palliyaarachchi, who works at the campus and can provide guidance and support to students. Overall, Parramatta South Campus is a dynamic and diverse educational institution within Western Sydney University, offering students a range of academic and extracurricular opportunities to enhance their learning experience.\n"
     ]
    }
   ],
   "source": [
    "def full_answer():\n",
    "    print(answer)\n",
    "    # print(\"-\" * 40)  # Adds a line of dashes as a separator \n",
    "    # for doc in retrieved_docs:\n",
    "    #     print(f'Page {doc.metadata[\"page\"]}: {doc.page_content[:300]}\\n')\n",
    "\n",
    "full_answer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liverpool Campus at Western Sydney University is located in the heart of the Liverpool Central Business District. The campus offers high-quality, technology-rich, and flexible teaching and learning spaces, as well as a dedicated floor for student life with study areas, a student kitchen, and areas to relax and socialize. It also provides nursing clinical practice units and has a whole floor dedicated to the library. The Ngara Ngura building is close to the Westfield Shopping Centre and the Macquarie Plaza, offering dining options, retail, and community amenities such as childcare. Additionally, it is conveniently located only 800m from the Liverpool transport hub.\n",
    "\n",
    "As a representative at Western Sydney University, I can provide you with more information about the facilities and programs offered at the Liverpool Campus. Whether you are interested in full-time or part-time study options, we have a range of programs available for you to choose from. The campus also hosts top facilities, including nursing clinical practice units, a whole floor library facility, and a technology-rich learning environment. If you have any specific questions or need assistance with enrolling at the Liverpool Campus, feel free to reach out to me for personalized guidance and support.\n",
    "\n",
    "If you are considering studying at Western Sydney University's Liverpool Campus, you can expect a modern and vibrant learning environment with access to top facilities and resources. The campus is designed to cater to the needs of over 1,000 students, providing a conducive space for academic growth and personal development. With a focus on technology-rich spaces, flexible study areas, and convenient amenities nearby, the Liverpool Campus offers a dynamic and supportive community for students pursuing their educational goals. Whether you are interested in nursing, criminal justice, community welfare, or other fields of study, the Liverpool Campus at Western Sydney University provides a welcoming and inclusive environment for your academic journey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GraphRag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
